# app/services/wecom_service.py
import xmltodict
import json
import logging
import datetime
import threading
import os
import mimetypes
import re
from sqlalchemy.orm import Session

from app.models import Message, MessageCursor, DeletedMessage, Customer
from app.services import (
    get_cursor_for_kfid, update_cursor_for_kfid, get_cached_access_token,
    download_media_file, get_db_for_async
)
from app.services.storage_service import storage
from app.utils.crypto import WXBizMsgCrypt
from app.core.config import (
    CORP_ID, TOKEN, ENCODING_AES_KEY, CALLBACK_STATUS,
    WECOM_API_BASE_URL, WECOM_API_PROXY_TOKEN
)


def reload_wecom_service_config():
    """
    çƒ­åŠ è½½ï¼šåˆ·æ–°æœ¬æ¨¡å—ä¸­ç¼“å­˜çš„ WeCom é…ç½®å˜é‡ã€‚
    WXBizMsgCrypt åœ¨æ¯æ¬¡è¯·æ±‚æ—¶é‡æ–°åˆ›å»ºï¼Œæ‰€ä»¥æ— éœ€é¢å¤–å¤„ç†ã€‚
    """
    global CORP_ID, TOKEN, ENCODING_AES_KEY, WECOM_API_BASE_URL, WECOM_API_PROXY_TOKEN
    from app.core.config import (
        CORP_ID as _cid, TOKEN as _tk, ENCODING_AES_KEY as _aes,
        WECOM_API_BASE_URL as _url, WECOM_API_PROXY_TOKEN as _pt
    )
    CORP_ID = _cid
    TOKEN = _tk
    ENCODING_AES_KEY = _aes
    WECOM_API_BASE_URL = _url
    WECOM_API_PROXY_TOKEN = _pt
    logging.getLogger("wecom").info("ğŸ”„ WeCom service config reloaded (wecom_service.py)")


def batch_get_customer_info(external_userid_list, db: Session):
    """
    æ‰¹é‡è·å–å®¢æˆ·è¯¦æƒ… (ä½¿ç”¨ batchget æ¥å£)
    API: https://developer.work.weixin.qq.com/document/path/95159
    """
    if not external_userid_list:
        return {}
    
    # å»é‡ & è¿‡æ»¤ç©ºå€¼
    external_userid_list = list(set([uid for uid in external_userid_list if uid]))
    if not external_userid_list:
        return {}

    # 1. ä¼˜å…ˆä»æ•°æ®åº“ç¼“å­˜æŸ¥
    results_map = {}
    
    # Check cache (Optional: add expiry logic later)
    cached_customers = db.query(Customer).filter(Customer.external_userid.in_(external_userid_list)).all()
    for cust in cached_customers:
        results_map[cust.external_userid] = cust.to_dict()
        
    # Filter out what we already have
    # (For now, we trust cache. In future, we might want to refresh if old)
    missing_ids = [uid for uid in external_userid_list if uid not in results_map]
    
    if not missing_ids:
        return results_map

    # 2. è°ƒç”¨ API è·å–ç¼ºå¤±çš„
    access_token = get_cached_access_token()
    url = f"{WECOM_API_BASE_URL}/cgi-bin/kf/customer/batchget?access_token={access_token}"
    
    # WeCom Limit: max 100 per request
    chunk_size = 100
    import requests
    
    for i in range(0, len(missing_ids), chunk_size):
        chunk = missing_ids[i:i + chunk_size]
        payload = {
            "external_userid_list": chunk
        }
        
        try:
            logger.info(f"ğŸ” Batch getting customer info for {len(chunk)} users")
            headers = {}
            if WECOM_API_PROXY_TOKEN:
                headers['X-Antigrv-Token'] = WECOM_API_PROXY_TOKEN

            response = requests.post(url, json=payload, headers=headers, timeout=10)
            res_json = response.json()
            
            if res_json.get('errcode') == 0:
                customer_list = res_json.get('customer_list', [])
                for cust_data in customer_list:
                    uid = cust_data.get('external_userid')
                    if not uid: continue
                    
                    nickname = cust_data.get('nickname')
                    avatar = cust_data.get('avatar')
                    gender = cust_data.get('gender')
                    
                    # Store/Update DB
                    customer = db.query(Customer).filter(Customer.external_userid == uid).first()
                    if not customer:
                        customer = Customer(external_userid=uid)
                        db.add(customer)
                    
                    customer.nickname = nickname
                    customer.avatar = avatar
                    customer.gender = gender
                    customer.extra_info = json.dumps(cust_data)
                    customer.updated_at = datetime.datetime.utcnow()
                    
                    results_map[uid] = customer.to_dict()
                
                db.commit()
            else:
                logger.error(f"âŒ Failed to batch get customers: {res_json}")
                
        except Exception as e:
            logger.error(f"âŒ Exception in batch_get_customer_info: {e}")
            
    return results_map


logger = logging.getLogger("wecom")


def verify_url(msg_signature, timestamp, nonce, echostr):
    """ä¼ä¸šå¾®ä¿¡URLéªŒè¯"""
    try:
        wxcpt = WXBizMsgCrypt(TOKEN, ENCODING_AES_KEY, CORP_ID)
        ret, sEchoStr = wxcpt.VerifyURL(msg_signature, timestamp, nonce, echostr)
        if ret != 0:
            CALLBACK_STATUS['last_error'] = f"VerifyURL failed: code={ret}"
            CALLBACK_STATUS['error_count'] = CALLBACK_STATUS.get('error_count', 0) + 1
            CALLBACK_STATUS['last_check'] = datetime.datetime.now()
            raise ValueError(f"VerifyURL failed with code {ret}")
        
        # Success
        CALLBACK_STATUS['last_success'] = datetime.datetime.now()
        CALLBACK_STATUS['last_error'] = None
        CALLBACK_STATUS['error_count'] = 0
        CALLBACK_STATUS['last_check'] = datetime.datetime.now()
        return sEchoStr
    except Exception as e:
        CALLBACK_STATUS['last_error'] = f"VerifyURL exception: {str(e)}"
        CALLBACK_STATUS['error_count'] = CALLBACK_STATUS.get('error_count', 0) + 1
        CALLBACK_STATUS['last_check'] = datetime.datetime.now()
        raise


def parse_xml_message(xml_content):
    """è§£æXMLæ ¼å¼çš„æ¶ˆæ¯"""
    try:
        return xmltodict.parse(xml_content)['xml']
    except Exception as e:
        logger.error("Parse XML failed: %s", str(e), exc_info=True)
        raise Exception(f"Parse XML failed: {str(e)}")


def sync_customer_service_messages(access_token, token, open_kfid, cursor=None, limit=1000, db=None):
    """
    åŒæ­¥å¾®ä¿¡å®¢æœæ¶ˆæ¯ - æ”¯æŒå¢é‡æ‹‰å–
    æ³¨æ„ï¼šæ­¤å‡½æ•°ä¸å†è‡ªåŠ¨æ›´æ–°æ•°æ®åº“cursorï¼Œè€Œæ˜¯è¿”å›æ•°æ®ç”±è°ƒç”¨è€…å†³å®šä½•æ—¶æ›´æ–°
    """
    import requests
    url = f"{WECOM_API_BASE_URL}/cgi-bin/kf/sync_msg?access_token={access_token}"

    payload = {
        "open_kfid": open_kfid,
        "limit": limit
    }

    if token:
        payload["token"] = token
    if cursor:
        payload["cursor"] = cursor

    logger.debug("Syncing messages with payload: %s", json.dumps(payload, ensure_ascii=False, indent=2))
    
    # æ„é€ è¯·æ±‚å¤´
    headers = {}
    if WECOM_API_PROXY_TOKEN:
        headers['X-Antigrv-Token'] = WECOM_API_PROXY_TOKEN

    logger.info(f"ğŸš€ Sending Sync Request to: {url} | Headers: {headers}")  # Debug Log

    try:
        response = requests.post(url, json=payload, headers=headers, timeout=30)
        result = response.json()

        # logger.info("Sync messages result: %s", json.dumps(result, ensure_ascii=False, indent=2))

        if result.get('errcode') == 0:
            msg_list = result.get('msg_list', [])
            logger.info(f"âœ… Synced {len(msg_list)} messages (has_more={result.get('has_more')})")
            return result
        else:
            raise Exception(f"Sync messages failed: {result.get('errmsg')}")
    except Exception as e:
        logger.error("Sync messages error: %s", str(e), exc_info=True)
        raise Exception(f"Sync messages error: {str(e)}")


def handle_customer_service_event(event_data, db: Session):
    """
    å¤„ç†å¾®ä¿¡å®¢æœäº‹ä»¶ - æ”¯æŒå¢é‡æ‹‰å–
    """
    try:
        event_type = event_data.get('Event', '')
        token = event_data.get('Token', '')
        open_kfid = event_data.get('OpenKfId', '')

        logger.debug("Handling customer service event: type=%s, token=%s, open_kfid=%s",
                    event_type, token, open_kfid)

        if event_type == 'kf_msg_or_event':
            access_token = get_cached_access_token()
            # logger.info("Got access_token for message sync")

            # è·å–å½“å‰cursor
            current_cursor = get_cursor_for_kfid(open_kfid, db)
            logger.debug(f"Current cursor for {open_kfid}: {current_cursor}")

            # åŒæ­¥æ¶ˆæ¯
            messages_data = sync_customer_service_messages(
                access_token=access_token,
                token=token,
                open_kfid=open_kfid,
                cursor=current_cursor,
                db=db
            )

            # å¤„ç†è·å–åˆ°çš„æ¶ˆæ¯
            processed_result = process_messages_async(messages_data, db)
            processed_count = processed_result.get('processed_count', 0)
            
            # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šåªæœ‰åœ¨æˆåŠŸå¤„ç†æ¶ˆæ¯åï¼Œæ‰æ›´æ–° cursor
            if 'next_cursor' in messages_data and messages_data['next_cursor']:
                update_success = update_cursor_for_kfid(
                    open_kfid, 
                    messages_data['next_cursor'], 
                    db
                )
                if update_success:
                    logger.info(f"âœ… Cursor updated successfully for {open_kfid}")
                else:
                    logger.error(f"âŒ Failed to update cursor for {open_kfid}")

            # å¦‚æœè¿˜æœ‰æ›´å¤šæ¶ˆæ¯ï¼Œç»§ç»­åŒæ­¥ï¼ˆé€’å½’è°ƒç”¨ï¼‰
            if messages_data.get('has_more') == 1:
                logger.info(f"More messages available for {open_kfid}, continuing sync...")
                return handle_customer_service_event(event_data, db)

            # ğŸ”¥ æ›´æ–°å›è°ƒçŠ¶æ€ (Sync Success)
            CALLBACK_STATUS['last_success'] = datetime.datetime.now()
            CALLBACK_STATUS['last_error'] = None
            CALLBACK_STATUS['error_count'] = 0
            CALLBACK_STATUS['last_check'] = datetime.datetime.now()

            return processed_result

        return {"status": "event_handled", "event_type": event_type}

    except Exception as e:
        logger.error("Handle customer service event failed: %s", str(e), exc_info=True)
        return {"error": str(e), "status": "failed"}


def process_messages_async(messages_data, db: Session):
    """
    å¤„ç†æ‹‰å–åˆ°çš„æ¶ˆæ¯ - ä¿å­˜åˆ°æ•°æ®åº“
    """
    try:
        msg_list = messages_data.get('msg_list', [])
        logger.info(f"Processing {len(msg_list)} messages")

        results = []
        processed_count = 0

        for msg in msg_list:
            msg_type = msg.get('msgtype', '')
            msg_id = msg.get('msgid')
            
            # æ£€æŸ¥æ˜¯å¦å·²åœ¨é»‘åå•ï¼ˆå·²åˆ é™¤ï¼‰ä¸­
            if db.query(DeletedMessage).filter(DeletedMessage.msgid == msg_id).first():
                logger.info(f"â­ï¸ Skipping deleted message: {msg_id}")
                processed_count += 1 # è§†ä¸ºå·²å¤„ç†ï¼Œè¿™æ ·å¯ä»¥æ¨è¿› cursor
                continue

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ (é¿å…é‡å¤æ’å…¥æŠ¥é”™)
            if db.query(Message).filter(Message.msgid == msg_id).first():
                logger.info(f"â­ï¸ Skipping existing message: {msg_id}")
                processed_count += 1
                continue

            logger.debug(f"Processing message type: {msg_type}")
            logger.debug(f"Raw message  %s", json.dumps(msg, ensure_ascii=False, indent=2))

            # åˆ›å»ºæ¶ˆæ¯è®°å½•
            # ä¿®æ­£æ—¶é—´ï¼šWeComè¿”å›çš„æ˜¯UTCæ—¶é—´æˆ³ï¼Œæˆ‘ä»¬éœ€è¦è½¬æ¢ä¸ºUTC+8æ˜¾ç¤º
            tz_sha = datetime.timezone(datetime.timedelta(hours=8))
            

            # æå–æ¶ˆæ¯å†…å®¹æ‘˜è¦
            content_summary = None
            if msg_type == 'text':
                content_summary = msg.get('text', {}).get('content')
            elif msg_type == 'image':
                content_summary = '[å›¾ç‰‡] ' + (msg.get('image', {}).get('filename') or 'image')
            elif msg_type == 'voice':
                content_summary = '[è¯­éŸ³] ' + (msg.get('voice', {}).get('filename') or 'voice message')
            elif msg_type == 'video':
                content_summary = '[è§†é¢‘] ' + (msg.get('video', {}).get('filename') or 'video message')
            elif msg_type == 'file':
                content_summary = '[æ–‡ä»¶] ' + (msg.get('file', {}).get('filename') or 'file')
            elif msg_type == 'location':
                loc = msg.get('location', {})
                content_summary = f"[ä½ç½®] {loc.get('address')} ({loc.get('name')})"
            elif msg_type == 'link':
                link = msg.get('link', {})
                content_summary = f"[é“¾æ¥] {link.get('title')} - {link.get('desc')}"
            elif msg_type == 'business_card':
                card = msg.get('business_card', {})
                content_summary = f"[åç‰‡] UserID: {card.get('userid')}"
            elif msg_type == 'miniprogram':
                mini = msg.get('miniprogram', {})
                content_summary = f"[å°ç¨‹åº] {mini.get('title')}"
            elif msg_type == 'merged_msg':
                merged = msg.get('merged_msg', {})
                content_summary = f"[èŠå¤©è®°å½•] {merged.get('title')}"
            
            message = Message(
                msgid=msg_id,
                open_kfid=msg.get('open_kfid'),
                external_userid=msg.get('external_userid'),
                servicer_userid=msg.get('servicer_userid', ''),
                msgtype=msg_type,
                send_time=datetime.datetime.fromtimestamp(msg.get('send_time', 0), tz_sha).replace(tzinfo=None), # å­˜ä¸ºnaive timeä½†å…¶å®æ˜¯UTC+8
                origin=msg.get('origin', 0),
                content=content_summary,  # å­˜å‚¨æ‘˜è¦å†…å®¹
                media_id=get_media_id_from_message(msg),
                extra_data=json.dumps(msg),  # ä¿å­˜åŸå§‹æ•°æ®
                download_status='success' if msg_type in ['text', 'location', 'link', 'business_card', 'miniprogram', 'merged_msg'] else 'pending'
            )

            # ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“
            db.add(message)
            processed_count += 1
            results.append({
                'msgid': message.msgid,
                'status': 'saved'
            })

        # æäº¤æ•°æ®åº“äº‹åŠ¡
        db.commit()
        logger.info(f"Successfully saved {processed_count} messages to database")

        # ä¸ºæ‰€æœ‰æ”¯æŒçš„æ¶ˆæ¯ç±»å‹å¯åŠ¨å¼‚æ­¥ä¸‹è½½
        SUPPORTED_MEDIA_TYPES = ['image', 'voice', 'video', 'file']

        for msg in msg_list:
            msg_type = msg.get('msgtype', '')
            if msg_type in SUPPORTED_MEDIA_TYPES:
                media_id = get_media_id_from_message(msg)
                if media_id:
                    file_info = get_file_info_from_message(msg)
                    msg_copy = {
                        'media_id': media_id,
                        'msgtype': msg_type,
                        'msgid': msg.get('msgid'),
                        'open_kfid': msg.get('open_kfid'),
                        'file_info': file_info
                    }
                    # å¯åŠ¨å¼‚æ­¥çº¿ç¨‹ä¸‹è½½åª’ä½“
                    thread = threading.Thread(
                        target=async_download_media,
                        args=(msg_copy,),
                        daemon=True
                    )
                    thread.start()
                    logger.debug(f"Started async media download for {msg_type} message {msg.get('msgid')}")
                else:
                    logger.warning(f"No media_id found for {msg_type} message {msg.get('msgid')}")

        return {
            'processed_count': processed_count,
            'results': results,
            'next_cursor': messages_data.get('next_cursor'),
            'has_more': messages_data.get('has_more', 0)
        }

    except Exception as e:
        db.rollback()
        logger.error("Process messages failed: %s", str(e), exc_info=True)
        raise Exception(f"Process messages failed: {str(e)}")


def async_download_media(msg_data):
    """å¼‚æ­¥ä¸‹è½½åª’ä½“æ–‡ä»¶ - ç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯"""
    db = None
    try:
        media_id = msg_data['media_id']
        msgtype = msg_data['msgtype']
        msgid = msg_data['msgid']
        file_info = msg_data.get('file_info', {})

        logger.debug(f"Async downloading media for message {msgid}, media_id: {media_id}, type: {msgtype}")

        # è·å–ç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯
        db = next(get_db_for_async())

        # ä¸‹è½½åª’ä½“æ–‡ä»¶
        media_content, filename_from_header = download_media_file(media_id, msgtype)

        if media_content:
            # æ„é€ æ–‡ä»¶å
            filename = file_info.get('filename', '')
            
            # --- å…³é”®ä¿®å¤ï¼šå¦‚æœä» file_info æ‹¿åˆ°çš„åå­—çœ‹èµ·æ¥åƒæ˜¯è‡ªåŠ¨ç”Ÿæˆçš„ï¼Œå°è¯•ç”¨ header é‡Œçš„çœŸå®åå­—è¦†ç›– ---
            # è‡ªåŠ¨ç”Ÿæˆçš„ç‰¹å¾ï¼šç©ºï¼Œæˆ–è€… startswith 'file_'/'image_'
            is_generic_name = not filename or filename.startswith(('file_', 'image_', 'voice_', 'video_'))
            if is_generic_name and filename_from_header:
                 logger.info(f"ğŸ”„ Replacing generic filename '{filename}' with header filename '{filename_from_header}'")
                 filename = filename_from_header
            
            extension = file_info.get('extension')
            # å¦‚æœæ²¡æœ‰æ‰©å±•åï¼Œå°è¯•ä» filename æå–
            if not extension and filename and '.' in filename:
                extension = filename.rsplit('.', 1)[-1]
            if not extension and filename_from_header and '.' in filename_from_header:
                 extension = filename_from_header.rsplit('.', 1)[-1]
            
            # ç¡®ä¿å”¯ä¸€æ€§å’Œç›®å½•ç»“æ„
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            import uuid
            random_str = str(uuid.uuid4())[:8]
            
            # 4. æ”¹è¿›çš„æ–‡ä»¶å‘½åç­–ç•¥ (ä¼˜å…ˆä¿ç•™åŸæ–‡ä»¶åï¼Œä½†é˜²æ­¢å†²çª)
            # å¦‚æœæœ‰åŸå§‹æ–‡ä»¶å (ä¸”ä¸æ˜¯é»˜è®¤ç”Ÿæˆçš„ text_... / image_...)
            is_default_name = filename.startswith(f"{msgtype}_") and 10 < len(filename) < 40
            
            # å®‰å…¨æ–‡ä»¶åå¤„ç†
            final_filename = ""
            if filename and not is_default_name:
                # å°è¯•ä¿ç•™åŸå§‹æ–‡ä»¶å: timestamp_originalName
                # å…è®¸ä¸­æ–‡ (\u4e00-\u9fff)
                safe_name = "".join([c for c in filename if c.isalpha() or c.isdigit() or c in (' ', '.', '-', '_') or '\u4e00' <= c <= '\u9fff']).strip()
                if len(safe_name) > 50:
                    safe_name = safe_name[:50]
                if not safe_name: safe_name = "file"
                
                # å»é™¤å¯èƒ½çš„é‡å¤åç¼€ (å¦‚æœ safe_name å·²ç»æœ‰åç¼€)
                base_name = safe_name
                if extension and safe_name.lower().endswith(f'.{extension}'):
                     base_name = safe_name.rsplit('.', 1)[0]
                
                final_filename = f"{timestamp}_{base_name}"
            else:
                # ä½¿ç”¨é»˜è®¤å‘½å
                final_filename = f"{timestamp}_{random_str}"

            # ç»Ÿä¸€æ·»åŠ åç¼€
            if extension and not final_filename.endswith(f'.{extension}'):
                final_filename = f"{final_filename}.{extension}"
            
            filename = final_filename # èµ‹å€¼å› filename å˜é‡ä»¥ä¾›åç»­ä½¿ç”¨
            
            # ğŸ”¥ å®‰å…¨ç‰¹æ€§ï¼šå¼ºåˆ¶é‡å‘½åå±é™©æ–‡ä»¶
            DANGEROUS_EXTENSIONS = {'exe', 'bat', 'sh', 'cmd', 'ps1', 'vbs', 'scr', 'com', 'js', 'dll', 'jar', 'iso', 'asp', 'aspx', 'php', 'jsp'}
            
            # æ£€æŸ¥ç”Ÿæˆçš„æœ¬åœ°æ–‡ä»¶å
            cur_ext = filename.rsplit('.', 1)[-1].lower() if '.' in filename else ""
            if cur_ext in DANGEROUS_EXTENSIONS:
                logger.warning(f"âš ï¸ Detected dangerous file extension form generated name: {filename}. Appending .dangerous")
                filename = f"{filename}.dangerous"
                
            # æ£€æŸ¥åŸå§‹æ–‡ä»¶å (å¦‚æœå­˜åœ¨ï¼Œä¹Ÿéœ€è¦é‡å‘½åï¼Œé˜²æ­¢ä¸‹è½½æ—¶æ¢å¤ä¸ºå±é™©åç¼€)
            if filename_from_header:
                 h_ext = filename_from_header.rsplit('.', 1)[-1].lower() if '.' in filename_from_header else ""
                 if h_ext in DANGEROUS_EXTENSIONS:
                      logger.warning(f"âš ï¸ Detected dangerous file extension from header: {filename_from_header}. Appending .dangerous")
                      filename_from_header = f"{filename_from_header}.dangerous"
            
            # æ„å»ºå­˜å‚¨Key (e.g. image/2023...jpg)
            # ä½¿ç”¨ msgtype ä½œä¸ºå­ç›®å½•
            storage_key = f"{msgtype}/{filename}"
                
            # ä¿å­˜åª’ä½“æ–‡ä»¶ (åˆ°S3æˆ–æœ¬åœ°)
            # ä¿å­˜åª’ä½“æ–‡ä»¶ (åˆ°S3æˆ–æœ¬åœ°)
            saved_path = storage.save_file(media_content, storage_key)

            if saved_path:
                # æ›´æ–°æ•°æ®åº“è®°å½•
                message = db.query(Message).filter(Message.msgid == msgid).first()
                if message:
                    if message.download_count is None:
                        message.download_count = 0
                    message.download_count += 1
                    
                    message.last_download_time = datetime.datetime.utcnow()
                    
                    # æ›´æ–°æ–‡ä»¶å“ˆå¸Œ
                    import hashlib
                    message.file_hash = hashlib.md5(media_content).hexdigest()[:16]
                    
                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ›´æ–°æ–‡ä»¶å¤§å°å’Œæ–‡ä»¶å
                    message.file_size = len(media_content)
                    # å¦‚æœåŸå§‹æ–‡ä»¶åä¸ºç©ºï¼Œæˆ–è€…ä½¿ç”¨äº†ä»Headerè·å–çš„æ›´å¥½æ–‡ä»¶åï¼Œåˆ™æ›´æ–°
                    if not message.original_filename or (filename_from_header and message.original_filename != filename_from_header):
                        # ä¼˜å…ˆä½¿ç”¨ Header ä¸­çš„æ–‡ä»¶å (å»é™¤å¯èƒ½çš„æ—¶é—´æˆ³å‰ç¼€? ä¸ï¼Œè¿™é‡Œ header ä¹Ÿå°±æ˜¯åŸå§‹å)
                        # å¦‚æœæ²¡æœ‰ header filenameï¼Œå°±ç”¨ final_filename (è™½å¸¦æ—¶é—´æˆ³ä½†æ€»æ¯” None å¥½)
                        message.original_filename = filename_from_header if filename_from_header else filename

                    # æ›´æ–° download_status
                    message.download_status = 'success'
                    
                    # æ›´æ–°æ–‡ä»¶è·¯å¾„ä¿¡æ¯
                    message.media_path = saved_path
                    # æ„é€ è®¿é—®URL (å‡è®¾å­˜å‚¨åœ¨ MEDIA_STORAGE_PATH ä¸‹ï¼Œé€šè¿‡ /media è®¿é—®)
                    # storage_key ç±»ä¼¼äº "video/20260210_123456.mp4"
                    message.media_url = f"/media/{storage_key}"

                    db.commit()
                    logger.info(f"âœ… Media downloaded and saved for msg {msgid}: {saved_path}")
                else:
                    logger.warning(f"âš ï¸ Message {msgid} found but DB record missing during update.")
            else:
                 logger.error(f"âŒ Storage failed to save file for msg {msgid}")

        else:
            # download_media_file è¿”å› None
            logger.error(f"âŒ Failed to download media content for msg {msgid}, media_id: {media_id}. content is None.")
            # å¯é€‰: æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸º failed
            message = db.query(Message).filter(Message.msgid == msgid).first()
            if message:
                message.download_status = 'failed'
                db.commit()

    except Exception as e:
        logger.error(f"âŒ Async media download thread failed for msg {msg_data.get('msgid')}: {e}", exc_info=True)
        # å°è¯•è®°å½•å¤±è´¥çŠ¶æ€
        try:
             if db:
                 message = db.query(Message).filter(Message.msgid == msg_data.get('msgid')).first()
                 if message:
                     message.download_status = 'failed'
                     message.download_error = str(e)
                     db.commit()
        except:
             pass
    finally:
        if db:
            db.close()


def get_media_id_from_message(msg):
    """ä»æ¶ˆæ¯ä¸­æå–media_id"""
    msgtype = msg.get('msgtype', '')
    logger.debug(f"Extracting media_id for msgtype: {msgtype}")
    media_id = None
    if msgtype == 'image':
        media_id = msg.get('image', {}).get('media_id')
        logger.debug(f"Image message media_id: {media_id}")
    elif msgtype == 'voice':
        media_id = msg.get('voice', {}).get('media_id')
        logger.debug(f"Voice message media_id: {media_id}")
    elif msgtype == 'video':
        media_id = msg.get('video', {}).get('media_id')
        logger.debug(f"Video message media_id: {media_id}")
    elif msgtype == 'file':
        # æ–‡ä»¶æ¶ˆæ¯ï¼Œmedia_id åœ¨ file å­—æ®µä¸­
        media_id = msg.get('file', {}).get('media_id')
        logger.debug(f"File message media_id: {media_id}")
    return media_id


def get_file_info_from_message(msg):
    """ä»æ¶ˆæ¯ä¸­æå–æ–‡ä»¶ä¿¡æ¯"""
    msgtype = msg.get('msgtype', '')
    logger.debug(f"Extracting file info for msgtype: {msgtype}")

    # åŸºç¡€æ–‡ä»¶ä¿¡æ¯
    file_info = {
        'filename': f"download_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}",
        'file_type': msgtype,
        'extension': '',
        'size': 0,
        'mime_type': ''
    }

    if msgtype == 'file':
        file_data = msg.get('file', {})
        logger.debug(f"File data received: %s", json.dumps(file_data, ensure_ascii=False, indent=2))

        # 1. ä»æ–‡ä»¶æ•°æ®ä¸­æå–æ–‡ä»¶å
        filename = file_data.get('filename', '')
        if not filename:
            filename = file_data.get('file_name', '')
        if not filename:
            filename = file_data.get('title', '')

        file_info['filename'] = filename if filename else f"file_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # 2. ä»æ–‡ä»¶åæå–æ‰©å±•å
        if '.' in file_info['filename']:
            file_info['extension'] = file_info['filename'].rsplit('.', 1)[-1].lower()

        # 3. æ–‡ä»¶å¤§å°
        file_size = file_data.get('file_size')
        if file_size:
            try:
                file_info['size'] = int(file_size)
            except (TypeError, ValueError):
                pass

        # 4. æ–‡ä»¶ç±»å‹/MIMEç±»å‹
        file_type = file_data.get('file_type', '').lower()
        file_info['file_type'] = file_type

        if file_type:
            # å¸¸è§æ–‡ä»¶ç±»å‹æ˜ å°„
            mime_map = {
                'txt': 'text/plain',
                'pdf': 'application/pdf',
                'doc': 'application/msword',
                'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                'xls': 'application/vnd.ms-excel',
                'xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                'ppt': 'application/vnd.ms-powerpoint',
                'pptx': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',
                'jpg': 'image/jpeg',
                'jpeg': 'image/jpeg',
                'png': 'image/png',
                'gif': 'image/gif',
                'bmp': 'image/bmp',
                'mp3': 'audio/mpeg',
                'amr': 'audio/amr',
                'wav': 'audio/wav',
                'mp4': 'video/mp4',
                'avi': 'video/x-msvideo',
                'mov': 'video/quicktime',
                'zip': 'application/zip',
                'rar': 'application/vnd.rar',
                '7z': 'application/x-7z-compressed'
            }

            if file_type in mime_map:
                file_info['mime_type'] = mime_map[file_type]
            else:
                # ä»æ‰©å±•åæ¨æ–­
                ext = file_info['extension']
                if ext and '.' + ext in mimetypes.types_map:
                    file_info['mime_type'] = mimetypes.types_map['.' + ext]
                else:
                    file_info['mime_type'] = f'application/{file_type}'

    elif msgtype == 'image':
        filename = msg.get('image', {}).get('filename', '')
        file_info['filename'] = filename if filename else f"image_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
        file_info['file_type'] = 'image'
        file_info['extension'] = 'jpg' if not filename or '.' not in filename else filename.rsplit('.', 1)[-1].lower()
        file_info['mime_type'] = 'image/jpeg' if file_info['extension'] == 'jpg' else f'image/{file_info["extension"]}'

    elif msgtype == 'voice':
        filename = msg.get('voice', {}).get('filename', '')
        file_info['filename'] = filename if filename else f"voice_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
        file_info['file_type'] = 'voice'
        file_info['extension'] = 'amr' if not filename or '.' not in filename else filename.rsplit('.', 1)[-1].lower()
        file_info['mime_type'] = 'audio/amr' if file_info['extension'] == 'amr' else f'audio/{file_info["extension"]}'

    elif msgtype == 'video':
        filename = msg.get('video', {}).get('filename', '')
        file_info['filename'] = filename if filename else f"video_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
        file_info['file_type'] = 'video'
        file_info['extension'] = 'mp4' if not filename or '.' not in filename else filename.rsplit('.', 1)[-1].lower()
        file_info['mime_type'] = 'video/mp4' if file_info['extension'] == 'mp4' else f'video/{file_info["extension"]}'

    # 5. ç¡®ä¿æœ‰æ‰©å±•å
    if not file_info['extension']:
        # ä»MIMEç±»å‹æ¨æ–­
        mime_type = file_info['mime_type']
        if mime_type:
            ext = mimetypes.guess_extension(mime_type)
            if ext:
                file_info['extension'] = ext.lstrip('.')

    # 6. ç¡®ä¿æœ‰æ–‡ä»¶å
    if '.' not in file_info['filename']:
        file_info['filename'] = f"{file_info['filename']}.{file_info['extension']}"

    logger.debug(f"Final file info: %s", json.dumps(file_info, ensure_ascii=False, indent=2))
    return file_info